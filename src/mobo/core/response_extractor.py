"""
Response extractor node for the LangGraph workflow.

This handles the final step of extracting the response content from LangGraph messages
and formatting it for Discord. The actual response generation happens in message_generator.
"""

import logging
import time

from .state import BotState, log_workflow_step, add_debug_info

logger = logging.getLogger(__name__)


def extract_final_response(state: BotState) -> str | None:
    """
    Extract final response from LLM messages.

    Returns:
        Response text if valid, None if extraction fails (bot should stay silent)
    """
    messages = state.get("messages", [])

    if not messages:
        logger.warning("No messages found in state")
        return None

    last_message = messages[-1]

    # Extract content from the message
    if hasattr(last_message, "content") and last_message.content:
        response = last_message.content
        if isinstance(response, list):
            # Handle potential list responses
            response = " ".join(str(item) for item in response)

        response_text = str(response).strip()
        if response_text:
            return response_text

    logger.warning("No valid content in last message")
    return None


async def simple_response_node(state: BotState) -> BotState:
    """
    Simple response node using standard LangGraph patterns.

    In modern LangGraph, the response is simply extracted from the
    last message after tool execution. No additional LLM call needed.
    """
    start_time = time.time()
    log_workflow_step(state, "response_generator")

    try:
        logger.info("ðŸ’¬ Extracting final response...")

        # Extract response using standard LangChain patterns
        response_text = extract_final_response(state)

        if response_text is not None:
            # Truncate safely if needed
            original_length = len(response_text)
            response_text = truncate_response_safely(response_text, 2000)

            if len(response_text) < original_length:
                logger.warning("âš ï¸ Response truncated to fit Discord limits")

            state["final_response"] = response_text
            add_debug_info(state, "response_length", len(response_text))
            logger.info(f"âœ… Response extracted ({len(response_text)} chars)")
            logger.debug(f"ðŸ’¬ Response: {response_text[:100]}...")
        else:
            # No valid response
            state["final_response"] = None
            logger.info("ðŸ”‡ No valid response extracted - bot will stay silent")

        # Update metadata
        execution_time = time.time() - start_time
        state["execution_time"] += execution_time
        add_debug_info(state, "response_extraction_time", execution_time)

        return state

    except Exception as e:
        logger.exception(f"âŒ Response extraction error: {e}")

        # Set response to None on error
        state["final_response"] = None
        add_debug_info(state, "response_error", str(e))

        execution_time = time.time() - start_time
        state["execution_time"] += execution_time

        return state


async def response_extractor_node(state: BotState) -> BotState:
    """
    Standard LangGraph response extractor node.

    Uses simple message extraction instead of additional LLM calls.
    This follows modern LangGraph patterns where the response is already
    generated by the message_generator node.
    """
    return await simple_response_node(state)


# =============================================================================
# UTILITY FUNCTIONS
# =============================================================================


def format_response_summary(state: BotState) -> str:
    """
    Create a human-readable summary of response extraction.
    """
    response = state["final_response"]

    lines = [
        "ðŸ’¬ Response Extraction:",
        f"   ðŸ“ Length: {len(response) if response else 0} characters",
        f"   ðŸ’­ Response: {response[:100] if response else 'None'}{'...' if response and len(response) > 100 else ''}",
    ]

    # Add debug info if available
    debug_info = state.get("debug_info", {})
    if "response_extraction_time" in debug_info:
        lines.append(
            f"   â±ï¸ Extraction Time: {debug_info['response_extraction_time']:.2f}s"
        )

    return "\n".join(lines)


def truncate_response_safely(response: str, max_length: int = 2000) -> str:
    """
    Safely truncate a response to fit Discord limits while preserving meaning.

    Args:
        response: The response to truncate
        max_length: Maximum allowed length

    Returns:
        Truncated response
    """
    if len(response) <= max_length:
        return response

    # Try to truncate at sentence boundaries
    sentences = response.split(". ")
    truncated = ""

    for sentence in sentences:
        test_length = len(truncated + sentence + ". ")
        if test_length > max_length - 10:  # Leave room for "..."
            break
        truncated += sentence + ". "

    # If we got at least some content, use it
    if len(truncated.strip()) > 50:
        return truncated.strip() + "..."

    # Otherwise, just hard truncate
    return response[: max_length - 3] + "..."
